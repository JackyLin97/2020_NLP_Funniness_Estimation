{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Funniness_Estimation_Regression_Task_1.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "153a710b734546ed81491110c8f36cae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6e43fd9b131d432eab2896cc30e1183a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_048afc019696419bbd3ecef4e0634e68",
              "IPY_MODEL_ee1213ec5621477dad2a603b86061f7a"
            ]
          }
        },
        "6e43fd9b131d432eab2896cc30e1183a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "048afc019696419bbd3ecef4e0634e68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5dd1dba1cc764205852f701373ec8a21",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 760289,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 760289,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_57e9ca3fc6fc412fa4040f4551ceeeac"
          }
        },
        "ee1213ec5621477dad2a603b86061f7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_06d82f568d8841b2a5fe9a7d8d223eab",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 760k/760k [01:08&lt;00:00, 11.1kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2719799768ec43129f503aa9178da047"
          }
        },
        "5dd1dba1cc764205852f701373ec8a21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "57e9ca3fc6fc412fa4040f4551ceeeac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "06d82f568d8841b2a5fe9a7d8d223eab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2719799768ec43129f503aa9178da047": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1345708108de4b9082f9d6ec230f0f39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d6f6a554125f40a49354732c12650d22",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ad703b8c211042fea49bc1c0ddd0536b",
              "IPY_MODEL_facc382b13d74c45995a8a9661a98a3c"
            ]
          }
        },
        "d6f6a554125f40a49354732c12650d22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ad703b8c211042fea49bc1c0ddd0536b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7fc4b4f3317a4fc29e42faa2e2e5a478",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_09ab4576a0d24b919746daab0fecd2fe"
          }
        },
        "facc382b13d74c45995a8a9661a98a3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bcef3b833a2f4c6bbe93a6db67178fcc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 677kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_819ce1e60f1544ae9a76021eb3e21824"
          }
        },
        "7fc4b4f3317a4fc29e42faa2e2e5a478": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "09ab4576a0d24b919746daab0fecd2fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bcef3b833a2f4c6bbe93a6db67178fcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "819ce1e60f1544ae9a76021eb3e21824": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoAuoSxKZogJ",
        "colab_type": "text"
      },
      "source": [
        "# Funniness Estimation Regression System"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oO_Pzm1cLKf4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "54c28a0e-94e9-41a5-ee5e-21d2b763c785"
      },
      "source": [
        "\"\"\"\n",
        "@author: Ziyang Lin\n",
        "         zlin19@sheffield.ac.uk\n",
        "         University of Sheffield, UK\n",
        "\"\"\"\n",
        "\n",
        "'''\n",
        "A system for\n",
        "\"Assessing the Funniness of Edited News Headlines (SemEval-2020)\" task 2.\n",
        "'''\n",
        "\n",
        "import random\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "import torch.utils.data as tud\n",
        "\n",
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import word_tokenize\n",
        "\n",
        "\n",
        "# fix the seeds to get consistent results before every training\n",
        "# loop in what follows\n",
        "def fix_seed(seed=1234):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "\n",
        "# Helper function to print the run time\n",
        "def run_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LchxscdyVAfV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_stats = []\n",
        "log_num = 0\n",
        "\n",
        "def add_training_stats(training_stats, log_num, MODEL_NAME, BATCH_SIZE, N_EPOCHS, LRATE, FRATE, EPS, WU, WDECAY, train_loss, val_loss, test_loss):\n",
        "    log_num += 1\n",
        "\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'log': log_num,\n",
        "            'Model Name': MODEL_NAME,\n",
        "            'Batch Size': BATCH_SIZE,\n",
        "            'N_Epochs': N_EPOCHS,\n",
        "            'lr': LRATE,\n",
        "            'fr': FRATE,\n",
        "            'eps': EPS,\n",
        "            'wu': WU,\n",
        "            'wd': WDECAY,\n",
        "            'Training Loss': train_loss,\n",
        "            'Valid. Loss': val_loss,\n",
        "            'Test Loss': test_loss\n",
        "        }\n",
        "    )\n",
        "    \n",
        "    return training_stats, log_num   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "circaXFnHUnq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "681c518b-c224-4347-b97e-46317ed052b7"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 12.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 32.1MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 38.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=bfeb84b01ec7e5ca04d52df1fd9b93aa1a7c553ebc5058a32bd08a8269e397bf\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1adxCqDFnGE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fc63bd42-ee12-4c40-cd64-cd87e4f0232a"
      },
      "source": [
        "# do computation on a GPU if possible \n",
        "if torch.cuda.is_available():\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  DEVICE='cuda:0'\n",
        "else:\n",
        "  DEVICE='cpu'\n",
        "\n",
        "print('Device is', DEVICE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device is cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcLgdOc_yGsF",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMmXYdN9GXNR",
        "colab_type": "text"
      },
      "source": [
        "## Read data from csv files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooKOsrf8MKrO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loc = 'gdrive/My Drive/subtask-1/train.csv'\n",
        "dev_loc = 'gdrive/My Drive/subtask-1/dev.csv'\n",
        "test_loc = 'gdrive/My Drive/subtask-1/test.csv'\n",
        "train = pd.read_csv(train_loc)  \n",
        "valid = pd.read_csv(dev_loc)\n",
        "test = pd.read_csv(test_loc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAA7mYMzMK1M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def processed_data_to_lists(train):\n",
        "    headls_words = [(origin_headl, new_word) for (origin_headl, new_word) in zip(train.original.to_list(), train.edit.to_list())]\n",
        "    labels_list = train.meanGrade.to_list()\n",
        "\n",
        "    # list of tuple for original headlines and new edited headlines\n",
        "    o_headls_n_headls = []\n",
        "    new_word_list = []\n",
        "    \n",
        "    for origin_headl, new_word in headls_words:\n",
        "      # pattern\n",
        "      p = re.compile(r'\\<(.*?)\\/\\>')\n",
        "      # get the normal version of the original headline\n",
        "      origin_word = ''.join(re.findall(p, origin_headl))\n",
        "      normal_origin_headl = p.sub(origin_word, origin_headl)\n",
        "      # get the new edited headline\n",
        "      new_headl = p.sub(new_word, origin_headl)\n",
        "      # pair them and put them into the list\n",
        "      o_headls_n_headls.append((normal_origin_headl,new_headl))\n",
        "\n",
        "      new_word_list.append(new_word)\n",
        "\n",
        "    o_headls = [i for i, j in o_headls_n_headls]\n",
        "    n_headls = [j for i, j in o_headls_n_headls]\n",
        "\n",
        "    return o_headls, n_headls, new_word_list, labels_list\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPEAi_Cf1Iqt",
        "colab_type": "text"
      },
      "source": [
        "## Get lists of headlines and list of labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSgjtdHRMK-q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "93410e29-9c4e-49d2-dd0b-8d4e88a27891"
      },
      "source": [
        "train_o_headls, train_n_headls, train_new_word_list, train_labels_list = processed_data_to_lists(train)\n",
        "valid_o_headls, valid_n_headls, valid_new_word_list, valid_labels_list = processed_data_to_lists(valid)\n",
        "test_o_headls, test_n_headls, test_new_word_list, test_labels_list = processed_data_to_lists(test)\n",
        "\n",
        "len(train_n_headls)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9652"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 416
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBCt5TCIDUtb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b90d5a14-db7a-40e0-a33e-535e6a59fcc6"
      },
      "source": [
        "# extra data for training\n",
        "\n",
        "train_loc_extra = 'gdrive/My Drive/subtask-1/train_funlines.csv'\n",
        "train_extra = pd.read_csv(train_loc_extra)\n",
        "train_o_headls_extra, train_n_headls_extra, train_new_word_list_extra, train_labels_list_extra = processed_data_to_lists(train_extra)\n",
        "\n",
        "train_n_headls = train_n_headls + train_n_headls_extra\n",
        "train_new_word_list = train_new_word_list + train_new_word_list_extra\n",
        "train_labels_list = train_labels_list + train_labels_list_extra\n",
        "\n",
        "len(train_n_headls)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17900"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 418
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndC5Vv0kudLZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkgCDCDPAsYp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import AlbertTokenizer\n",
        "\n",
        "# Load the ALBERT tokenizer.\n",
        "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jv4kh-0XdS3l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "153a710b734546ed81491110c8f36cae",
            "6e43fd9b131d432eab2896cc30e1183a",
            "048afc019696419bbd3ecef4e0634e68",
            "ee1213ec5621477dad2a603b86061f7a",
            "5dd1dba1cc764205852f701373ec8a21",
            "57e9ca3fc6fc412fa4040f4551ceeeac",
            "06d82f568d8841b2a5fe9a7d8d223eab",
            "2719799768ec43129f503aa9178da047"
          ]
        },
        "outputId": "2b8a3eba-b02d-4738-8643-6e4879a5c046"
      },
      "source": [
        "from transformers import AlbertTokenizer\n",
        "\n",
        "# Load the ALBERT tokenizer.\n",
        "tokenizer = AlbertTokenizer.from_pretrained('albert-xxlarge-v2', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "153a710b734546ed81491110c8f36cae",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=760289.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtS6GhTOz8DW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "1345708108de4b9082f9d6ec230f0f39",
            "d6f6a554125f40a49354732c12650d22",
            "ad703b8c211042fea49bc1c0ddd0536b",
            "facc382b13d74c45995a8a9661a98a3c",
            "7fc4b4f3317a4fc29e42faa2e2e5a478",
            "09ab4576a0d24b919746daab0fecd2fe",
            "bcef3b833a2f4c6bbe93a6db67178fcc",
            "819ce1e60f1544ae9a76021eb3e21824"
          ]
        },
        "outputId": "aee3a030-0ad2-4c6c-e071-8ff19015bb7b"
      },
      "source": [
        "from transformers import ElectraTokenizer\n",
        "\n",
        "# Load the ELECTRA tokenizer.\n",
        "tokenizer = ElectraTokenizer.from_pretrained('google/electra-base-discriminator', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1345708108de4b9082f9d6ec230f0f39",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkU2GWh5XUtG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import XLNetTokenizer \n",
        "\n",
        "# Load the XLNet tokenizer.\n",
        "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKNmwLrzudWC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "9b949a63-df9c-40f4-e065-029a6a8b98a3"
      },
      "source": [
        "print(' Original: ', train_o_headls[0])\n",
        "\n",
        "print('Tokenized: ', tokenizer.tokenize(train_o_headls[0]))\n",
        "\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(train_o_headls[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  France is ‘ hunting down its citizens who joined Isis ’ without trial in Iraq\n",
            "Tokenized:  ['▁france', '▁is', '▁', '‘', '▁hunting', '▁down', '▁its', '▁citizens', '▁who', '▁joined', '▁is', 'is', '▁', '’', '▁without', '▁trial', '▁in', '▁iraq']\n",
            "Token IDs:  [714, 25, 13, 1, 5038, 125, 82, 2888, 72, 670, 25, 403, 13, 1, 366, 2178, 19, 4903]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "De9MytTHAITV",
        "colab_type": "text"
      },
      "source": [
        "## Max sequence length for BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb5crsr9udgo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eab83238-0c2a-44ce-b45f-5e3b73c6f3c7"
      },
      "source": [
        "max_one_len = 0\n",
        "\n",
        "\"\"\"for headl in train_o_headls:\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(headl, add_special_tokens=True)\n",
        "    # Update the maximum sentence length.\n",
        "    max_one_len = max(max_one_len, len(input_ids))\n",
        "\n",
        "print('Max sequence length for concatenation: ', (max_one_len-1)*2)\n",
        "print('Max sequence length for \\'sentence + word\\': ', max_one_len+2)\"\"\"\n",
        "\n",
        "for headl in train_n_headls:\n",
        "    headl = headl.split()\n",
        "    max_one_len = max(len(headl), max_one_len)\n",
        "\n",
        "print('Max sequence length: ', max_one_len + 4 )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sequence length:  31\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oE6vMueW_kf8",
        "colab_type": "text"
      },
      "source": [
        "## Get encoded inputs for BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJGCW4pC2XG7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "08507e9b-c763-4513-e2c5-5d7062d0dca7"
      },
      "source": [
        "# the version that concatenates original sentences and new sentences\n",
        "train_encoded_inputs = tokenizer(train_o_headls, train_n_headls, padding='max_length', max_length=90, truncation=True, return_tensors=\"pt\")\n",
        "valid_encoded_inputs = tokenizer(valid_o_headls, valid_n_headls, padding='max_length', max_length=90, truncation=True, return_tensors=\"pt\")\n",
        "test_encoded_inputs = tokenizer(test_o_headls, test_n_headls, padding='max_length', max_length=90, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "train_encoded_inputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101,  2605,  2003,  ...,     0,     0,     0],\n",
              "        [  101, 20864,  4447,  ...,     0,     0,     0],\n",
              "        [  101, 10399,  7610,  ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [  101,  8592,  2240,  ...,     0,     0,     0],\n",
              "        [  101,  3996,  2610,  ...,     0,     0,     0],\n",
              "        [  101,  2182,  1005,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0]])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 334
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8uEmS7YIIsG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "596e5e1c-844f-4bc6-a96b-b1e026a53557"
      },
      "source": [
        "# the version that only contains new sentences\n",
        "train_encoded_inputs = tokenizer(train_n_headls, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "valid_encoded_inputs = tokenizer(valid_n_headls, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "test_encoded_inputs = tokenizer(test_n_headls, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "train_encoded_inputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[    2,   714,    25,  ...,     0,     0,     0],\n",
              "        [    2, 21213,  2810,  ...,     0,     0,     0],\n",
              "        [    2, 10659,  6736,  ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [    2,  6581,   293,  ...,     0,     0,     0],\n",
              "        [    2,  2368,   698,  ...,     0,     0,     0],\n",
              "        [    2,   235,    13,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0]])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zfxi-7fKXYap",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "a0b8b505-da7c-4287-9035-4af4482f6045"
      },
      "source": [
        "# the version that concatenates new sentences and new words\n",
        "\n",
        "train_encoded_inputs = tokenizer(train_n_headls, train_new_word_list, padding='max_length', max_length=38, truncation=True, return_tensors=\"pt\")\n",
        "valid_encoded_inputs = tokenizer(valid_n_headls, valid_new_word_list, padding='max_length', max_length=38, truncation=True, return_tensors=\"pt\")\n",
        "test_encoded_inputs = tokenizer(test_n_headls, test_new_word_list, padding='max_length', max_length=38, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "# best so far: max_length=38\n",
        "train_encoded_inputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101,  2605,  2003,  ...,     0,     0,     0],\n",
              "        [  101, 20864,  4447,  ...,     0,     0,     0],\n",
              "        [  101, 10399,  7610,  ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [  101, 15432,  6284,  ...,     0,     0,     0],\n",
              "        [  101,  3533, 20996,  ...,     0,     0,     0],\n",
              "        [  101,  2096,  7513,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0]])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 420
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjUbZTv15O4q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a639bcc5-8acc-4033-f1df-a3b66444ea9f"
      },
      "source": [
        "train_input_ids = train_encoded_inputs['input_ids']\n",
        "train_attention_mask = train_encoded_inputs['attention_mask']\n",
        "train_token_type_ids = train_encoded_inputs['token_type_ids']\n",
        "train_labels = torch.tensor(train_labels_list)\n",
        "\n",
        "valid_input_ids = valid_encoded_inputs['input_ids']\n",
        "valid_attention_mask = valid_encoded_inputs['attention_mask']\n",
        "valid_token_type_ids = valid_encoded_inputs['token_type_ids']\n",
        "valid_labels = torch.tensor(valid_labels_list)\n",
        "\n",
        "test_input_ids = test_encoded_inputs['input_ids']\n",
        "test_attention_mask = test_encoded_inputs['attention_mask']\n",
        "test_token_type_ids = test_encoded_inputs['token_type_ids']\n",
        "test_labels = torch.tensor(test_labels_list)\n",
        "\n",
        "train_token_type_ids[0]\n",
        "tokenizer.decode(train_input_ids.tolist()[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'[CLS] pentagon claims 2, 000 % increase in russian trolls after bowling strikes. what does that mean? [SEP] bowling [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 421
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_G4N1_nHDBS",
        "colab_type": "text"
      },
      "source": [
        "## Prepare mini-batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFBTt-rLGwOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BERT_Dataset(tud.Dataset):\n",
        "    def __init__(self, x1, x2, x3, y1):\n",
        "        self.len = x1.shape[0]\n",
        "\n",
        "        self.x1_data = x1.to(DEVICE)\n",
        "        self.x2_data = x2.to(DEVICE)\n",
        "        self.x3_data = x3.to(DEVICE)\n",
        "        self.y1_data = y1.to(DEVICE)\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x1_data[index], self.x2_data[index], self.x3_data[index], self.y1_data[index]\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAv8-n4iFcN0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "f9dee5ab-9256-402c-8212-ad8af3fe9628"
      },
      "source": [
        "fix_seed()\n",
        "# Batching for BERT\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "train_dataset = BERT_Dataset(train_input_ids, train_attention_mask, train_token_type_ids, train_labels)\n",
        "valid_dataset = BERT_Dataset(valid_input_ids, valid_attention_mask, valid_token_type_ids, valid_labels)\n",
        "test_dataset = BERT_Dataset(test_input_ids, test_attention_mask, test_token_type_ids, test_labels)\n",
        "\n",
        "train_dataloader = tud.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "valid_dataloader = tud.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_dataloader = tud.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "\n",
        "##### demo #####\n",
        "print(train_dataloader)\n",
        "\n",
        "for x1, x2, x3, y1 in train_dataloader:\n",
        "    demo_x1 = x1\n",
        "    demo_x2 = x2\n",
        "    demo_x3 = x3\n",
        "    demo_y1 = y1\n",
        "    break\n",
        "    \n",
        "print(x1.shape)\n",
        "print(x2.shape)\n",
        "print(x3.shape)\n",
        "print(y1.shape)\n",
        "print(len(train_dataloader))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7faf0dcb2f60>\n",
            "torch.Size([16, 38])\n",
            "torch.Size([16, 38])\n",
            "torch.Size([16, 38])\n",
            "torch.Size([16])\n",
            "1119\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7SP8TiKLcL2",
        "colab_type": "text"
      },
      "source": [
        "# Training Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nx-ADOt3MlHg",
        "colab_type": "text"
      },
      "source": [
        "## Define train and evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oL8RT5k2Bn5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define train_BERT and evaluate_BERT for the concatenation version\n",
        "def train_BERT(model, train_dataloader, valid_dataloader, optimizer, scheduler, criterion, N_EPOCHS):\n",
        "    fix_seed()\n",
        "    model = model.to(DEVICE)\n",
        "\n",
        "    # Measure the total time for the whole run.\n",
        "    t0 = time.time()\n",
        "\n",
        "    for epoch in range(N_EPOCHS):\n",
        "    \n",
        "        start_time = time.time()\n",
        "\n",
        "        # To ensure the dropout is \"turned on\" while training\n",
        "        model.train()\n",
        "        \n",
        "        epoch_loss = 0\n",
        "    \n",
        "        for input_ids_batch, attention_mask_batch, token_type_ids_batch, labels in train_dataloader:\n",
        "                        \n",
        "            # Zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # shape(input_ids_batch) = [B, T]\n",
        "            # shape(attention_mask_batch) = [B, T]\n",
        "            # shape(labels) = [B]\n",
        "\n",
        "            # get the output\n",
        "            outputs = model(input_ids_batch,\n",
        "                            attention_mask=attention_mask_batch,\n",
        "                            token_type_ids=token_type_ids_batch)\n",
        "            \n",
        "            # get the predictions & calculate the loss\n",
        "            predictions = outputs[0].squeeze(1)\n",
        "            loss = criterion(predictions, labels)\n",
        "                      \n",
        "            # calculate the gradient of each parameter\n",
        "            loss.backward()\n",
        "        \n",
        "            # update the parameters using the gradients and optimizer algorithm \n",
        "            optimizer.step()\n",
        "\n",
        "            # update the learning rate\n",
        "            scheduler.step()\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "            \n",
        "        average_epoch_loss = epoch_loss / len(train_dataloader)\n",
        "        \n",
        "        end_time = time.time()\n",
        "               \n",
        "        epoch_mins, epoch_secs = run_time(start_time, end_time)\n",
        "    \n",
        "        average_epoch_valid_loss = evaluate_BERT(model, criterion, valid_dataloader)\n",
        "\n",
        "        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "        print(f'\\tTrain Loss: {average_epoch_loss:.5f} |')\n",
        "        print(f'\\t Val. Loss: {average_epoch_valid_loss:.5f} |')\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"***Completed***\")\n",
        "    total_mins, total_secs = run_time(t0, time.time())\n",
        "    print(f'Total time spent: {total_mins}m {total_secs}s')\n",
        "\n",
        "    return average_epoch_loss, average_epoch_valid_loss\n",
        "\n",
        "\n",
        "def evaluate_BERT(model, criterion, dataloader):\n",
        "    fix_seed()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    # Turn on evaluate mode. This de-activates dropout. \n",
        "    model.eval()\n",
        "\n",
        "    # We do not compute gradients within this block, i.e. no training\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for input_ids_batch, attention_mask_batch, token_type_ids_batch, labels in dataloader:\n",
        "            \n",
        "            # get the output\n",
        "            outputs = model(input_ids_batch,\n",
        "                            attention_mask=attention_mask_batch,\n",
        "                            token_type_ids=token_type_ids_batch)\n",
        "\n",
        "            predictions = outputs[0].squeeze(1)\n",
        "            loss = criterion(predictions, labels)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o3KL6BCnKEW2",
        "colab": {}
      },
      "source": [
        "# define train_BERT and evaluate_BERT for only-new-sentences version\n",
        "def train_BERT(model, train_dataloader, valid_dataloader, optimizer, scheduler, criterion, N_EPOCHS):\n",
        "    fix_seed()\n",
        "    model = model.to(DEVICE)\n",
        "\n",
        "    # Measure the total time for the whole run.\n",
        "    t0 = time.time()\n",
        "\n",
        "    for epoch in range(N_EPOCHS):\n",
        "    \n",
        "        start_time = time.time()\n",
        "\n",
        "        # To ensure the dropout is \"turned on\" while training\n",
        "        model.train()\n",
        "        \n",
        "        epoch_loss = 0\n",
        "    \n",
        "        for input_ids_batch, attention_mask_batch, token_type_ids_batch, labels in train_dataloader:\n",
        "                        \n",
        "            # Zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # shape(input_ids_batch) = [B, T]\n",
        "            # shape(attention_mask_batch) = [B, T]\n",
        "            # shape(labels) = [B]\n",
        "\n",
        "            # get the output\n",
        "            outputs = model(input_ids_batch,\n",
        "                            attention_mask=attention_mask_batch)\n",
        "            \n",
        "            # get the predictions & calculate the loss\n",
        "            predictions = outputs[0].squeeze(1)\n",
        "            loss = criterion(predictions, labels)\n",
        "                      \n",
        "            # calculate the gradient of each parameter\n",
        "            loss.backward()\n",
        "        \n",
        "            # update the parameters using the gradients and optimizer algorithm \n",
        "            optimizer.step()\n",
        "\n",
        "            # update the learning rate\n",
        "            scheduler.step()\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "            \n",
        "        average_epoch_loss = epoch_loss / len(train_dataloader)\n",
        "        \n",
        "        end_time = time.time()\n",
        "               \n",
        "        epoch_mins, epoch_secs = run_time(start_time, end_time)\n",
        "    \n",
        "        average_epoch_valid_loss = evaluate_BERT(model, criterion, valid_dataloader)\n",
        "\n",
        "        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "        print(f'\\tTrain Loss: {average_epoch_loss:.5f} |')\n",
        "        print(f'\\t Val. Loss: {average_epoch_valid_loss:.5f} |')\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"***Completed***\")\n",
        "    total_mins, total_secs = run_time(t0, time.time())\n",
        "    print(f'Total time spent: {total_mins}m {total_secs}s')\n",
        "\n",
        "    return average_epoch_loss, average_epoch_valid_loss\n",
        "\n",
        "\n",
        "def evaluate_BERT(model, criterion, dataloader):\n",
        "    fix_seed()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    # Turn on evaluate mode. This de-activates dropout. \n",
        "    model.eval()\n",
        "\n",
        "    # We do not compute gradients within this block, i.e. no training\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for input_ids_batch, attention_mask_batch, token_type_ids_batch, labels in dataloader:\n",
        "            \n",
        "            # get the output\n",
        "            outputs = model(input_ids_batch,\n",
        "                            attention_mask=attention_mask_batch)\n",
        "\n",
        "            predictions = outputs[0].squeeze(1)\n",
        "            loss = criterion(predictions, labels)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsKLHwkSjU7R",
        "colab_type": "text"
      },
      "source": [
        "## Load BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-c-l3GY-CM5F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import AlbertForSequenceClassification, AdamW\n",
        "\n",
        "# Load the AlbertForSequenceClassification model\n",
        "model = AlbertForSequenceClassification.from_pretrained(\"albert-base-v2\",\n",
        "                                                        num_labels = 1,   \n",
        "                                                        output_attentions = False,\n",
        "                                                        output_hidden_states = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd8s9CZpXo9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import XLNetForSequenceClassification, AdamW\n",
        "\n",
        "# Load the XLNetForSequenceClassification model\n",
        "model = XLNetForSequenceClassification.from_pretrained('xlnet-base-cased',\n",
        "                                                    num_labels = 1,   \n",
        "                                                    output_attentions = False,\n",
        "                                                    output_hidden_states = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLuszp3W2HS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import ElectraForSequenceClassification, AdamW\n",
        "\n",
        "# Load the ElectraForSequenceClassification model\n",
        "model = ElectraForSequenceClassification.from_pretrained(\"google/electra-base-discriminator\",\n",
        "                                                        num_labels = 1,   \n",
        "                                                        output_attentions = False,\n",
        "                                                        output_hidden_states = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gybOiDOojZHJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW\n",
        "\n",
        "# Load the BertForSequenceClassification model\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
        "                                                        num_labels = 1,   \n",
        "                                                        output_attentions = False,\n",
        "                                                        output_hidden_states = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfnCDZLLUuVj",
        "colab_type": "text"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlF41zJHKurw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters for BERT:\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4.\n",
        "N_EPOCHS = 1\n",
        "\n",
        "LRATE = 8e-3\n",
        "FRATE = 3e-5\n",
        "EPS = 1e-8\n",
        "WU = 0.2\n",
        "WDECAY = 0.005\n",
        "\n",
        "# best so far: N_EPOCHS = 2, LRATE = 8e-3, FRATE = 3e-5 EPS = 1e-8, WU = 0.3, WDECAY = 0.01\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "TOTSTEPS = len(train_dataloader) * N_EPOCHS * 2\n",
        "WUSTEPS = int(TOTSTEPS * WU)\n",
        "\n",
        "# Apply weight decay to all parameters other than bias and layer normalization terms\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "\"\"\"optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': WDECAY},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\"\"\"\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if \"bert\" not in n], 'lr': LRATE, 'weight_decay': WDECAY},\n",
        "    {'params': [p for n, p in model.named_parameters() if \"bert\" in n], 'weight_decay': WDECAY}\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Y55KlMtWSvV",
        "colab_type": "text"
      },
      "source": [
        "## Optimizer & Learning Rate Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg-o8bvyBoDx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the optimizer, \n",
        "# the epsilon parameter is a very small number to prevent any division by zero\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=FRATE, eps = EPS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6uz9uWdBoH6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = WUSTEPS,\n",
        "                                            num_training_steps = TOTSTEPS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JW_sGxxu2SmU",
        "colab_type": "text"
      },
      "source": [
        "## Define RMSE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvmRByfm2QYr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define rmse\n",
        "def rmse(predictions, labels):\n",
        "    loss = torch.sqrt(((predictions - labels)**2).mean())\n",
        "\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uv3-MI3pX2tr",
        "colab_type": "text"
      },
      "source": [
        "## Start training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7uePPEGBoMu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "935cf0cc-3e06-47ff-a0ee-4a76cb62c8cc"
      },
      "source": [
        "criterion = rmse\n",
        "\n",
        "train_loss, val_loss = train_BERT(model,\n",
        "                                  train_dataloader,\n",
        "                                  valid_dataloader,\n",
        "                                  optimizer,\n",
        "                                  scheduler,\n",
        "                                  criterion,\n",
        "                                  N_EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 4m 50s\n",
            "\tTrain Loss: 0.58582 |\n",
            "\t Val. Loss: 0.51137 |\n",
            "\n",
            "***Completed***\n",
            "Total time spent: 5m 1s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2m3M1cTNYNSu",
        "colab_type": "text"
      },
      "source": [
        "# Testing Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-l7wTEcYWIX",
        "colab_type": "text"
      },
      "source": [
        "## Start testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh7K06WzOXvl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a392f60b-a9d4-4abe-f1de-12b3125c2281"
      },
      "source": [
        "fix_seed()\n",
        "model.eval()\n",
        "\n",
        "test_input_ids = test_input_ids.to(DEVICE)\n",
        "test_attention_mask = test_attention_mask.to(DEVICE)\n",
        "test_token_type_ids = test_token_type_ids.to(DEVICE)\n",
        "test_labels = test_labels.to(DEVICE)\n",
        "\n",
        "with torch.no_grad():\n",
        "  test_predictions = model(test_input_ids,\n",
        "                           attention_mask=test_attention_mask,\n",
        "                           token_type_ids=test_token_type_ids)[0].squeeze(1)\n",
        "  test_loss = torch.sqrt(((test_predictions - test_labels)**2).mean()).item()\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.5f} |')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Test Loss: 0.52763 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fk0nsayzYNtb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fef4ff4c-4f9c-4de9-9949-0437006fbf82"
      },
      "source": [
        "fix_seed()\n",
        "\n",
        "test_loss = 0\n",
        "test_logits_all = torch.tensor([], device=DEVICE)\n",
        "\n",
        "# Turn on evaluate mode. This de-activates dropout. \n",
        "model.eval()\n",
        "\n",
        "# We do not compute gradients within this block, i.e. no training\n",
        "with torch.no_grad():\n",
        "\n",
        "    for input_ids_batch, attention_mask_batch, token_type_ids_batch, labels in test_dataloader:\n",
        "        \n",
        "        # get the output\n",
        "        outputs = model(input_ids_batch,\n",
        "                        attention_mask=attention_mask_batch,\n",
        "                        token_type_ids=token_type_ids_batch)\n",
        "\n",
        "        logits_batch = outputs[0].squeeze(1)\n",
        "        loss_batch = rmse(logits_batch, labels)\n",
        "        #test_logits_all += logits_batch.tolist()\n",
        "        test_logits_all = torch.cat((test_logits_all, logits_batch), 0)\n",
        "\n",
        "        test_loss += loss_batch.item()\n",
        "\n",
        "    average_test_loss = test_loss / len(test_dataloader)\n",
        "\n",
        "print(f'Test Loss: {average_test_loss:.5f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.51948\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmXyjzmkArMp",
        "colab_type": "text"
      },
      "source": [
        "## Write results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxAE4aJZQcyY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d2ab9bfd-3f46-4d7d-a1ca-997cef0ff05d"
      },
      "source": [
        "def write_predictions(predictions, test_data_frame, out_loc):\n",
        "    test_data_frame['pred'] = predictions\n",
        "    output = test_data_frame[['id','pred']]\n",
        "    output.to_csv(out_loc, index=False)\n",
        "        \n",
        "    print('Output file created:\\n\\t- '+os.path.abspath(out_loc))\n",
        "\n",
        "\n",
        "# write the predictions for the dev data into 'task-1-output.csv'\n",
        "out_loc = 'gdrive/My Drive/subtask-1/task-1-output.csv'\n",
        "write_predictions(test_predictions.cpu(), test, out_loc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output file created:\n",
            "\t- /content/gdrive/My Drive/subtask-1/task-1-output.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvRyvLeCFaPD",
        "colab_type": "text"
      },
      "source": [
        "## Check final results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzKVlMTJ88tg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "95b85347-50ce-4b96-8200-ea569ed7bd25"
      },
      "source": [
        "def score(truth_loc, prediction_loc):\n",
        "    truth = pd.read_csv(truth_loc, usecols=['id','meanGrade'])\n",
        "    pred = pd.read_csv(prediction_loc, usecols=['id','pred'])\n",
        "    \n",
        "    assert(sorted(truth.id) == sorted(pred.id)),\"ID mismatch between ground truth and prediction!\"\n",
        "    \n",
        "    data = pd.merge(truth,pred)\n",
        "    rmse = np.sqrt(np.mean((data['meanGrade'] - data['pred'])**2))\n",
        "    \n",
        "    print(\"RMSE = %.6f\" % rmse)\n",
        "\n",
        "    return rmse   \n",
        "\n",
        "# print RMSE\n",
        "truth_loc = 'gdrive/My Drive/subtask-1/test.csv'\n",
        "prediction_loc = 'gdrive/My Drive/subtask-1/task-1-output.csv'\n",
        "test_loss = score(truth_loc, prediction_loc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE = 0.527628\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tyk_hoF8safd",
        "colab_type": "text"
      },
      "source": [
        "# Logging Statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwpzJ5MG886_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "B1 = \"bert-base-uncased\"\n",
        "A2 = \"albert-base-v2\"\n",
        "A2XX = \"albert-xxlarge-v2\"\n",
        "E = \"electra\"\n",
        "XL = \"xlnet\"\n",
        "B1M = \"bert-base-uncased more_data\"\n",
        "B1MS = \"BertBaseUncasedMDataStp*2\"\n",
        "\n",
        "training_stats, log_num = add_training_stats(training_stats, \n",
        "                                             log_num,\n",
        "                                             B1MS,\n",
        "                                             BATCH_SIZE, \n",
        "                                             N_EPOCHS,\n",
        "                                             \"{:.0e}\".format(LRATE),\n",
        "                                             \"{:.0e}\".format(FRATE), \n",
        "                                             \"{:.0e}\".format(EPS), \n",
        "                                             WU,\n",
        "                                             WDECAY, \n",
        "                                             train_loss,\n",
        "                                             val_loss,\n",
        "                                             test_loss\n",
        "                                             )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMDDYWnLsZiO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b8b1dc04-5d95-49db-af3d-19c2bd2fb1fc"
      },
      "source": [
        "# Display floats with five decimal places.\n",
        "pd.set_option('precision', 5)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'log' as the row index.\n",
        "df_stats = df_stats.set_index('log')\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model Name</th>\n",
              "      <th>Batch Size</th>\n",
              "      <th>N_Epochs</th>\n",
              "      <th>lr</th>\n",
              "      <th>fr</th>\n",
              "      <th>eps</th>\n",
              "      <th>wu</th>\n",
              "      <th>wd</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Test Loss</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>log</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bert-base-uncased</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>8e-03</td>\n",
              "      <td>3e-05</td>\n",
              "      <td>1e-08</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.59192</td>\n",
              "      <td>0.54155</td>\n",
              "      <td>0.54946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bert-base-uncased</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>8e-03</td>\n",
              "      <td>3e-05</td>\n",
              "      <td>1e-08</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.51444</td>\n",
              "      <td>0.53222</td>\n",
              "      <td>0.54059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bert-base-uncased</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>8e-03</td>\n",
              "      <td>3e-05</td>\n",
              "      <td>1e-08</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.52616</td>\n",
              "      <td>0.53481</td>\n",
              "      <td>0.54498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bert-base-uncased</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>8e-03</td>\n",
              "      <td>3e-05</td>\n",
              "      <td>1e-08</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.52624</td>\n",
              "      <td>0.53648</td>\n",
              "      <td>0.54421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>bert-base-uncased</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>8e-03</td>\n",
              "      <td>3e-05</td>\n",
              "      <td>1e-08</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.52289</td>\n",
              "      <td>0.53178</td>\n",
              "      <td>0.54142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>bert-base-uncased</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>8e-03</td>\n",
              "      <td>3e-05</td>\n",
              "      <td>1e-08</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.50253</td>\n",
              "      <td>0.52634</td>\n",
              "      <td>0.54085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>bert-base-uncased</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>8e-03</td>\n",
              "      <td>3e-05</td>\n",
              "      <td>1e-08</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.51758</td>\n",
              "      <td>0.52993</td>\n",
              "      <td>0.53935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>bert-base-uncased</td>\n",
              "      <td>32</td>\n",
              "      <td>2</td>\n",
              "      <td>9e-03</td>\n",
              "      <td>3e-05</td>\n",
              "      <td>1e-08</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.53778</td>\n",
              "      <td>0.53758</td>\n",
              "      <td>0.54469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>bert-base-uncased</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>9e-03</td>\n",
              "      <td>3e-05</td>\n",
              "      <td>1e-08</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.49362</td>\n",
              "      <td>0.52963</td>\n",
              "      <td>0.53184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>bert-base-uncased</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>9e-03</td>\n",
              "      <td>3e-05</td>\n",
              "      <td>1e-08</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.49701</td>\n",
              "      <td>0.53673</td>\n",
              "      <td>0.53775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>bert-base-uncased</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>8e-03</td>\n",
              "      <td>3e-05</td>\n",
              "      <td>1e-08</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.50129</td>\n",
              "      <td>0.52963</td>\n",
              "      <td>0.52991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>bert-base-uncased</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>8e-03</td>\n",
              "      <td>3e-05</td>\n",
              "      <td>1e-08</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.50001</td>\n",
              "      <td>0.53022</td>\n",
              "      <td>0.52937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>bert-base-uncased</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>7e-03</td>\n",
              "      <td>3e-05</td>\n",
              "      <td>1e-08</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.50445</td>\n",
              "      <td>0.53777</td>\n",
              "      <td>0.53763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>bert-base-uncased</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>8e-03</td>\n",
              "      <td>3e-05</td>\n",
              "      <td>1e-08</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.50526</td>\n",
              "      <td>0.53614</td>\n",
              "      <td>0.53758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>bert-base-uncased</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>9e-03</td>\n",
              "      <td>3e-05</td>\n",
              "      <td>1e-08</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.50020</td>\n",
              "      <td>0.52845</td>\n",
              "      <td>0.53042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>bert-base-uncased</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>9e-03</td>\n",
              "      <td>3e-05</td>\n",
              "      <td>1e-08</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.50772</td>\n",
              "      <td>0.53581</td>\n",
              "      <td>0.53681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>bert-base-uncased</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>8e-03</td>\n",
              "      <td>3e-05</td>\n",
              "      <td>1e-08</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.47793</td>\n",
              "      <td>0.52280</td>\n",
              "      <td>0.53182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>bert-base-uncased</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>8e-03</td>\n",
              "      <td>3e-05</td>\n",
              "      <td>1e-08</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.47143</td>\n",
              "      <td>0.50682</td>\n",
              "      <td>0.53211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>electra</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>8e-03</td>\n",
              "      <td>3e-05</td>\n",
              "      <td>1e-08</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.58381</td>\n",
              "      <td>0.56950</td>\n",
              "      <td>0.57619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>electra</td>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "      <td>8e-03</td>\n",
              "      <td>1e-04</td>\n",
              "      <td>1e-08</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.57928</td>\n",
              "      <td>0.56740</td>\n",
              "      <td>0.57484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>electra</td>\n",
              "      <td>32</td>\n",
              "      <td>2</td>\n",
              "      <td>1e-02</td>\n",
              "      <td>1e-04</td>\n",
              "      <td>1e-06</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.58473</td>\n",
              "      <td>0.57374</td>\n",
              "      <td>0.57525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>electra</td>\n",
              "      <td>16</td>\n",
              "      <td>7</td>\n",
              "      <td>3e-02</td>\n",
              "      <td>3e-04</td>\n",
              "      <td>1e-06</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.57700</td>\n",
              "      <td>0.56668</td>\n",
              "      <td>0.57495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>electra</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>3e-02</td>\n",
              "      <td>8e-04</td>\n",
              "      <td>1e-06</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.57743</td>\n",
              "      <td>0.56674</td>\n",
              "      <td>0.57475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>bert-base-uncased more_data</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>8e-03</td>\n",
              "      <td>3e-05</td>\n",
              "      <td>1e-08</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.49500</td>\n",
              "      <td>0.54836</td>\n",
              "      <td>0.55294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>bert-base-uncased more_data</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>8e-03</td>\n",
              "      <td>3e-05</td>\n",
              "      <td>1e-08</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.57849</td>\n",
              "      <td>0.53592</td>\n",
              "      <td>0.54489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>bert-base-uncased more_data</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>8e-03</td>\n",
              "      <td>3e-05</td>\n",
              "      <td>1e-08</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.58669</td>\n",
              "      <td>0.54261</td>\n",
              "      <td>0.55147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>bert-base-uncased more_data</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>8e-03</td>\n",
              "      <td>3e-05</td>\n",
              "      <td>1e-08</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.57558</td>\n",
              "      <td>0.54906</td>\n",
              "      <td>0.55774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>bert-base-uncased more_data</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>8e-03</td>\n",
              "      <td>3e-05</td>\n",
              "      <td>1e-08</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.47568</td>\n",
              "      <td>0.53434</td>\n",
              "      <td>0.54234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>BertBaseUncasedMDataStp*2</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>8e-03</td>\n",
              "      <td>3e-05</td>\n",
              "      <td>1e-08</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.58154</td>\n",
              "      <td>0.51204</td>\n",
              "      <td>0.52356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>BertBaseUncasedMDataStp*2</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>8e-03</td>\n",
              "      <td>3e-05</td>\n",
              "      <td>1e-08</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.58520</td>\n",
              "      <td>0.50942</td>\n",
              "      <td>0.52737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>BertBaseUncasedMDataStp*2</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>8e-03</td>\n",
              "      <td>3e-05</td>\n",
              "      <td>1e-08</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.58951</td>\n",
              "      <td>0.53278</td>\n",
              "      <td>0.54507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>BertBaseUncasedMDataStp*2</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>8e-03</td>\n",
              "      <td>3e-05</td>\n",
              "      <td>1e-08</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.57718</td>\n",
              "      <td>0.50693</td>\n",
              "      <td>0.52054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>BertBaseUncasedMDataStp*2</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>8e-03</td>\n",
              "      <td>3e-05</td>\n",
              "      <td>1e-08</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.57701</td>\n",
              "      <td>0.50710</td>\n",
              "      <td>0.52078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>BertBaseUncasedMDataStp*2</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>8e-03</td>\n",
              "      <td>3e-05</td>\n",
              "      <td>1e-08</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.58582</td>\n",
              "      <td>0.51137</td>\n",
              "      <td>0.52763</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      Model Name  Batch Size  ...  Valid. Loss Test Loss\n",
              "log                                           ...                       \n",
              "1              bert-base-uncased          16  ...      0.54155   0.54946\n",
              "2              bert-base-uncased          16  ...      0.53222   0.54059\n",
              "3              bert-base-uncased          16  ...      0.53481   0.54498\n",
              "4              bert-base-uncased          16  ...      0.53648   0.54421\n",
              "5              bert-base-uncased          16  ...      0.53178   0.54142\n",
              "6              bert-base-uncased           8  ...      0.52634   0.54085\n",
              "7              bert-base-uncased          16  ...      0.52993   0.53935\n",
              "8              bert-base-uncased          32  ...      0.53758   0.54469\n",
              "9              bert-base-uncased          16  ...      0.52963   0.53184\n",
              "10             bert-base-uncased          16  ...      0.53673   0.53775\n",
              "11             bert-base-uncased          16  ...      0.52963   0.52991\n",
              "12             bert-base-uncased          16  ...      0.53022   0.52937\n",
              "13             bert-base-uncased          16  ...      0.53777   0.53763\n",
              "14             bert-base-uncased          16  ...      0.53614   0.53758\n",
              "15             bert-base-uncased          16  ...      0.52845   0.53042\n",
              "16             bert-base-uncased          16  ...      0.53581   0.53681\n",
              "17             bert-base-uncased           8  ...      0.52280   0.53182\n",
              "18             bert-base-uncased           4  ...      0.50682   0.53211\n",
              "19                       electra          16  ...      0.56950   0.57619\n",
              "20                       electra          16  ...      0.56740   0.57484\n",
              "21                       electra          32  ...      0.57374   0.57525\n",
              "22                       electra          16  ...      0.56668   0.57495\n",
              "23                       electra          16  ...      0.56674   0.57475\n",
              "24   bert-base-uncased more_data          16  ...      0.54836   0.55294\n",
              "25   bert-base-uncased more_data          16  ...      0.53592   0.54489\n",
              "26   bert-base-uncased more_data          16  ...      0.54261   0.55147\n",
              "27   bert-base-uncased more_data          16  ...      0.54906   0.55774\n",
              "28   bert-base-uncased more_data          16  ...      0.53434   0.54234\n",
              "29     BertBaseUncasedMDataStp*2          16  ...      0.51204   0.52356\n",
              "30     BertBaseUncasedMDataStp*2          16  ...      0.50942   0.52737\n",
              "31     BertBaseUncasedMDataStp*2          16  ...      0.53278   0.54507\n",
              "32     BertBaseUncasedMDataStp*2          16  ...      0.50693   0.52054\n",
              "33     BertBaseUncasedMDataStp*2          16  ...      0.50710   0.52078\n",
              "34     BertBaseUncasedMDataStp*2          16  ...      0.51137   0.52763\n",
              "\n",
              "[34 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 578
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFQZM8plDQyK",
        "colab_type": "text"
      },
      "source": [
        "## Write statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fg7-KYSf58QC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log_loc = 'gdrive/My Drive/subtask-1/log_2.csv'\n",
        "df_stats.to_csv(log_loc, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1ZBR3Gx7Egy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljGh7wNTs03L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_stats.pop(-1)\n",
        "log_num -= 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EhK7_QcDtfG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}