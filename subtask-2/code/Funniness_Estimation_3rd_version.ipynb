{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Funniness_Estimation_3rd_version.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "572a840af87b43fb93f424627ac0264c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_365bfc6654064212bbf7605308e50511",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_76e868caf98c465986a678134da53dfa",
              "IPY_MODEL_46177bd43743427a857195ab415ca218"
            ]
          }
        },
        "365bfc6654064212bbf7605308e50511": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "76e868caf98c465986a678134da53dfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a7826afea2c14809baf1f9b9c7bff974",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a2c41acfe33b4c63ad39f8a1b31a3ef7"
          }
        },
        "46177bd43743427a857195ab415ca218": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_db84b6245af54d67b59897a27337fb55",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 697kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_da94259a162f468e86fbd01ddc73b502"
          }
        },
        "a7826afea2c14809baf1f9b9c7bff974": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a2c41acfe33b4c63ad39f8a1b31a3ef7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "db84b6245af54d67b59897a27337fb55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "da94259a162f468e86fbd01ddc73b502": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7d2f9cc3d6034d91aab76cf7f3345c08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7c7724f0b8c34c33ae4fdd7cc0a1c2e6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7eaa21b6f4854691b3953f0d55aba62a",
              "IPY_MODEL_e220f4d152b446159e4f4594d02ca799"
            ]
          }
        },
        "7c7724f0b8c34c33ae4fdd7cc0a1c2e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7eaa21b6f4854691b3953f0d55aba62a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_331be50cffee446c9b61c775b3f017b5",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898823,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898823,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8af773b688fc4a569a778ee9fd3ec058"
          }
        },
        "e220f4d152b446159e4f4594d02ca799": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6a44fb1398cf46319844390221b48489",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 899k/899k [00:03&lt;00:00, 262kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d738308c1a774e8b90c016eb9715515b"
          }
        },
        "331be50cffee446c9b61c775b3f017b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8af773b688fc4a569a778ee9fd3ec058": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6a44fb1398cf46319844390221b48489": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d738308c1a774e8b90c016eb9715515b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5caa41f0da9f497890456fc065f1626d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c7970ea715fb4db2999965d7f410b667",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1f1daa95dd2e4f3eaf2b519611eb35e2",
              "IPY_MODEL_cbf2c2ed9fe2472ba119c149cb06de20"
            ]
          }
        },
        "c7970ea715fb4db2999965d7f410b667": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1f1daa95dd2e4f3eaf2b519611eb35e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_66f2b0532803426cab1ce6c3543bed82",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f27113a24a89484da69da46ef5276785"
          }
        },
        "cbf2c2ed9fe2472ba119c149cb06de20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f03817c937844cbf9e15739a1268b99a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 456kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ddc365d135f14dd59533ea2657fde70f"
          }
        },
        "66f2b0532803426cab1ce6c3543bed82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f27113a24a89484da69da46ef5276785": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f03817c937844cbf9e15739a1268b99a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ddc365d135f14dd59533ea2657fde70f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoAuoSxKZogJ",
        "colab_type": "text"
      },
      "source": [
        "# Funniness Estimation System v3.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oO_Pzm1cLKf4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "d1c17227-10c1-4828-87c5-705e543bb11f"
      },
      "source": [
        "\"\"\"\n",
        "@author: Ziyang Lin\n",
        "         zlin19@sheffield.ac.uk\n",
        "         University of Sheffield, UK\n",
        "\"\"\"\n",
        "\n",
        "'''\n",
        "A system for\n",
        "\"Assessing the Funniness of Edited News Headlines (SemEval-2020)\" task 2.\n",
        "'''\n",
        "\n",
        "import random\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "import torch.utils.data as tud\n",
        "\n",
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import word_tokenize\n",
        "\n",
        "\n",
        "# fix the seeds to get consistent results before every training\n",
        "# loop in what follows\n",
        "def fix_seed(seed=123):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "\n",
        "# Helper function to print the run time\n",
        "def run_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/gdrive\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LchxscdyVAfV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log_num = 0\n",
        "training_stats = []\n",
        "\n",
        "def add_training_stats(training_stats, log_num, MODEL_NAME, BATCH_SIZE, N_EPOCHS, LRATE, FRATE, EPS, WU, WDECAY, train_loss, train_accuracy, val_loss, val_accuracy, test_accuracy):\n",
        "    log_num += 1\n",
        "\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'log': log_num,\n",
        "            'Model Name': MODEL_NAME,\n",
        "            'Batch Size': BATCH_SIZE,\n",
        "            'N_Epochs': N_EPOCHS,\n",
        "            'lr': LRATE,\n",
        "            'fr': FRATE,\n",
        "            'eps': EPS,\n",
        "            'wu': WU,\n",
        "            'wd': WDECAY,\n",
        "            'Training Loss': train_loss,\n",
        "            'Training Accur.': train_accuracy,\n",
        "            'Valid. Loss': val_loss,\n",
        "            'Valid. Accur.': val_accuracy,\n",
        "            'Testing Accur.': test_accuracy\n",
        "        }\n",
        "    )\n",
        "    \n",
        "    return training_stats, log_num"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "circaXFnHUnq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "8b075924-5fa7-4c03-b9ee-647dadda67a8"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 778kB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 29.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 59.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.0MB 56.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=c039d2c9121ffbf52608ff258499a8ba1f62f2abf86186b90076f38ac033bb86\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1adxCqDFnGE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "23c51aaa-54fd-421c-a442-f604ef13673b"
      },
      "source": [
        "# do computation on a GPU if possible \n",
        "if torch.cuda.is_available():\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  DEVICE='cuda:0'\n",
        "else:\n",
        "  DEVICE='cpu'\n",
        "\n",
        "print('Device is', DEVICE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device is cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcLgdOc_yGsF",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMmXYdN9GXNR",
        "colab_type": "text"
      },
      "source": [
        "## Read data from csv files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooKOsrf8MKrO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loc = 'gdrive/My Drive/subtask-2/train.csv'\n",
        "dev_loc = 'gdrive/My Drive/subtask-2/dev.csv'\n",
        "test_loc = 'gdrive/My Drive/subtask-2/test.csv'\n",
        "train = pd.read_csv(train_loc)  \n",
        "valid = pd.read_csv(dev_loc)\n",
        "test = pd.read_csv(test_loc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAA7mYMzMK1M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For the normal version:\n",
        "\n",
        "def get_edited_headlines_list(headls_words):\n",
        "    # list of new edited headlines\n",
        "    headls_list = []\n",
        "    \n",
        "    for origin_headl, new_word in headls_words:\n",
        "      # pattern\n",
        "      p = re.compile(r'\\<(.*?)\\/\\>')\n",
        "      # get the new edited headline\n",
        "      new_headl = p.sub(new_word, origin_headl)\n",
        "      # add it to the list\n",
        "      headls_list.append(new_headl)\n",
        "\n",
        "    return headls_list\n",
        "\n",
        "\n",
        "def processed_data_to_lists(train):\n",
        "    headls_words_1 = [(origin_headl_1, new_word_1) for (origin_headl_1, new_word_1) in zip(train.original1.to_list(), train.edit1.to_list())]\n",
        "    headls_words_2 = [(origin_headl_2, new_word_2) for (origin_headl_2, new_word_2) in zip(train.original2.to_list(), train.edit2.to_list())]\n",
        "    labels_list = train.label.to_list()\n",
        "\n",
        "    headls_1 = get_edited_headlines_list(headls_words_1)\n",
        "    headls_2 = get_edited_headlines_list(headls_words_2)\n",
        "\n",
        "    return headls_1, headls_2, labels_list\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU9sjB-Qxt9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For cut-headlines version:\n",
        "\n",
        "def cut_headline(new_word, new_headl, num_context):\n",
        "    # does not consider the words in the very first and very last of the sentences\n",
        "    # could be improved\n",
        "    new_headl_split = new_headl.split()\n",
        "\n",
        "    for index, word in enumerate(new_headl_split):\n",
        "       if word.strip(\",'\\\".!\") == new_word:\n",
        "           break\n",
        "    return \" \".join(new_headl_split[index-num_context:index] + new_headl_split[index:index+(num_context+1)])\n",
        "\n",
        "\n",
        "def get_edited_headlines_list_cut(headls_words, num_context):\n",
        "    # list of new edited headlines\n",
        "    headls_list = []\n",
        "    \n",
        "    for origin_headl, new_word in headls_words:\n",
        "      # pattern\n",
        "      p = re.compile(r'\\<(.*?)\\/\\>')\n",
        "      # get the new edited headline\n",
        "      new_headl = p.sub(new_word, origin_headl)\n",
        "      # cut the new_headl\n",
        "      cut_new_headl = cut_headline(new_word, new_headl, num_context)\n",
        "      # add it to the list\n",
        "      headls_list.append(cut_new_headl)\n",
        "\n",
        "    return headls_list\n",
        "\n",
        "\n",
        "def processed_data_to_lists_cut(train, num_context):\n",
        "    headls_words_1 = [(origin_headl_1, new_word_1) for (origin_headl_1, new_word_1) in zip(train.original1.to_list(), train.edit1.to_list())]\n",
        "    headls_words_2 = [(origin_headl_2, new_word_2) for (origin_headl_2, new_word_2) in zip(train.original2.to_list(), train.edit2.to_list())]\n",
        "    labels_list = train.label.to_list()\n",
        "\n",
        "    headls_1 = get_edited_headlines_list_cut(headls_words_1, num_context)\n",
        "    headls_2 = get_edited_headlines_list_cut(headls_words_2, num_context)\n",
        "\n",
        "    return headls_1, headls_2, labels_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xT5fy-7vEHg5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For the punctuation removal and new words returned version:\n",
        "\n",
        "def remove_punctuation(sentence):\n",
        "    words = nltk.word_tokenize(sentence)\n",
        "\n",
        "    # isalnum() -> word that only contain alphanumeric characters\n",
        "    new_words = [word for word in words if word.isalnum()]\n",
        "    # Use map() method for mapping str (for converting elements in list to string) with given iterator\n",
        "    new_sentence = ' '.join(map(str, new_words))\n",
        "\n",
        "    return new_sentence\n",
        "\n",
        "\n",
        "def get_edited_headlines_list_pv(headls_words):\n",
        "    # list of new edited headlines\n",
        "    headls_list = []\n",
        "    \n",
        "    for origin_headl, new_word in headls_words:\n",
        "      # pattern\n",
        "      p = re.compile(r'\\<(.*?)\\/\\>')\n",
        "      # get the new edited headline\n",
        "      new_headl = p.sub(new_word, origin_headl)\n",
        "      # remove punctuations\n",
        "      new_headl = remove_punctuation(new_headl)\n",
        "      # add it to the list\n",
        "      headls_list.append(new_headl)\n",
        "\n",
        "    return headls_list\n",
        "\n",
        "\n",
        "def processed_data_to_lists_pv(train):\n",
        "    headls_words_1 = [(origin_headl_1, new_word_1) for (origin_headl_1, new_word_1) in zip(train.original1.to_list(), train.edit1.to_list())]\n",
        "    headls_words_2 = [(origin_headl_2, new_word_2) for (origin_headl_2, new_word_2) in zip(train.original2.to_list(), train.edit2.to_list())]\n",
        "    labels_list = train.label.to_list()\n",
        "\n",
        "    headls_1 = get_edited_headlines_list_pv(headls_words_1)\n",
        "    headls_2 = get_edited_headlines_list_pv(headls_words_2)\n",
        "\n",
        "    new_words_1 = [new_word_1 for (origin_headl_1, new_word_1) in headls_words_1]\n",
        "    new_words_2 = [new_word_2 for (origin_headl_2, new_word_2) in headls_words_2]\n",
        "\n",
        "    return headls_1, headls_2, labels_list, new_words_1, new_words_2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPEAi_Cf1Iqt",
        "colab_type": "text"
      },
      "source": [
        "## Get lists of headlines and list of labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSgjtdHRMK-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For the normal version:\n",
        "\n",
        "train_headls_1, train_headls_2, train_labels_list = processed_data_to_lists(train)\n",
        "valid_headls_1, valid_headls_2, valid_labels_list = processed_data_to_lists(valid)\n",
        "test_headls_1, test_headls_2, test_labels_list = processed_data_to_lists(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRDkb1jY1ExM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For cut-headlines version:\n",
        "\n",
        "num_context = 4\n",
        "\n",
        "train_headls_1, train_headls_2, train_labels_list = processed_data_to_lists_cut(train, num_context)\n",
        "valid_headls_1, valid_headls_2, valid_labels_list = processed_data_to_lists_cut(valid, num_context)\n",
        "test_headls_1, test_headls_2, test_labels_list = processed_data_to_lists_cut(test, num_context)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAjWUVJ1Hb2S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For the punctuation removal and new words returned version:\n",
        "\n",
        "train_headls_1, train_headls_2, train_labels_list, train_new_words_1, train_new_words_2 = processed_data_to_lists_pv(train)\n",
        "valid_headls_1, valid_headls_2, valid_labels_list, valid_new_words_1, valid_new_words_2  = processed_data_to_lists_pv(valid)\n",
        "test_headls_1, test_headls_2, test_labels_list, test_new_words_1, test_new_words_2 = processed_data_to_lists_pv(test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndC5Vv0kudLZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "572a840af87b43fb93f424627ac0264c",
            "365bfc6654064212bbf7605308e50511",
            "76e868caf98c465986a678134da53dfa",
            "46177bd43743427a857195ab415ca218",
            "a7826afea2c14809baf1f9b9c7bff974",
            "a2c41acfe33b4c63ad39f8a1b31a3ef7",
            "db84b6245af54d67b59897a27337fb55",
            "da94259a162f468e86fbd01ddc73b502"
          ]
        },
        "outputId": "c6f72d78-2f6f-47f0-c3cc-651becdf4922"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "572a840af87b43fb93f424627ac0264c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkgCDCDPAsYp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import AlbertTokenizer\n",
        "\n",
        "# Load the ALBERT tokenizer.\n",
        "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtS6GhTOz8DW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import ElectraTokenizer\n",
        "\n",
        "# Load the ELECTRA tokenizer.\n",
        "tokenizer = ElectraTokenizer.from_pretrained('google/electra-base-discriminator', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUjbnE9Ke2as",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "7d2f9cc3d6034d91aab76cf7f3345c08",
            "7c7724f0b8c34c33ae4fdd7cc0a1c2e6",
            "7eaa21b6f4854691b3953f0d55aba62a",
            "e220f4d152b446159e4f4594d02ca799",
            "331be50cffee446c9b61c775b3f017b5",
            "8af773b688fc4a569a778ee9fd3ec058",
            "6a44fb1398cf46319844390221b48489",
            "d738308c1a774e8b90c016eb9715515b",
            "5caa41f0da9f497890456fc065f1626d",
            "c7970ea715fb4db2999965d7f410b667",
            "1f1daa95dd2e4f3eaf2b519611eb35e2",
            "cbf2c2ed9fe2472ba119c149cb06de20",
            "66f2b0532803426cab1ce6c3543bed82",
            "f27113a24a89484da69da46ef5276785",
            "f03817c937844cbf9e15739a1268b99a",
            "ddc365d135f14dd59533ea2657fde70f"
          ]
        },
        "outputId": "cd59f953-9b04-4cb2-a665-25ed1efe1b6f"
      },
      "source": [
        "from transformers import RobertaTokenizer\n",
        "\n",
        "# Load the Roberta tokenizer.\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d2f9cc3d6034d91aab76cf7f3345c08",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5caa41f0da9f497890456fc065f1626d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkU2GWh5XUtG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import XLNetTokenizer \n",
        "\n",
        "# Load the XLNet tokenizer.\n",
        "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKNmwLrzudWC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7ff45efc-bf3c-4886-85ba-84421deceb16"
      },
      "source": [
        "print(' Original: ', train_headls_1[0])\n",
        "\n",
        "print('Tokenized: ', tokenizer.tokenize(train_headls_1[0]))\n",
        "\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(train_headls_1[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  \" Gene Cernan , Last Dancer on the Moon , Dies at 82 \"\n",
            "Tokenized:  ['\"', 'gene', 'ce', '##rna', '##n', ',', 'last', 'dancer', 'on', 'the', 'moon', ',', 'dies', 'at', '82', '\"']\n",
            "Token IDs:  [1000, 4962, 8292, 12789, 2078, 1010, 2197, 8033, 2006, 1996, 4231, 1010, 8289, 2012, 6445, 1000]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "De9MytTHAITV",
        "colab_type": "text"
      },
      "source": [
        "## Max sequence length for pretrain LMs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb5crsr9udgo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0be81bfe-a897-4fe7-b62c-fb1db89e4ce7"
      },
      "source": [
        "max_one_len = 0\n",
        "\"\"\"\n",
        "for headl in train_headls_1:\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(headl, add_special_tokens=True)\n",
        "    # Update the maximum sentence length.\n",
        "    max_one_len = max(max_one_len, len(input_ids))\n",
        "\n",
        "print('Max sequence length: ', (max_one_len-1)*2)\n",
        "\"\"\"\n",
        "for headl in train_headls_1:\n",
        "    headl = headl.split()\n",
        "    max_one_len = max(len(headl), max_one_len)\n",
        "\n",
        "print('Max sequence length: ', (max_one_len * 2) + 3 )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sequence length:  55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oE6vMueW_kf8",
        "colab_type": "text"
      },
      "source": [
        "## Get encoded inputs for pretrain LMs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJGCW4pC2XG7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "030131b4-ac34-4954-83c2-c4f8b7d5a976"
      },
      "source": [
        "train_encoded_inputs = tokenizer(train_headls_1, train_headls_2, padding='max_length', max_length=55, truncation=True, return_tensors=\"pt\")\n",
        "valid_encoded_inputs = tokenizer(valid_headls_1, valid_headls_2, padding='max_length', max_length=55, truncation=True, return_tensors=\"pt\")\n",
        "test_encoded_inputs = tokenizer(test_headls_1, test_headls_2, padding='max_length', max_length=55, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "#45\n",
        "train_encoded_inputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101,  1000,  4962,  ...,     0,     0,     0],\n",
              "        [  101,  1000,  1045,  ...,     0,     0,     0],\n",
              "        [  101,  1000,  1045,  ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [  101,  1523,  2009,  ...,  3043,  1524,   102],\n",
              "        [  101,  1523, 12849,  ...,  3302,  1029,   102],\n",
              "        [  101,  1523,  2365,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0,  ..., 1, 1, 1],\n",
              "        [0, 0, 0,  ..., 1, 1, 1],\n",
              "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [1, 1, 1,  ..., 1, 1, 1],\n",
              "        [1, 1, 1,  ..., 1, 1, 1],\n",
              "        [1, 1, 1,  ..., 0, 0, 0]])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjUbZTv15O4q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "3e523768-d5bb-408b-ef86-eeef7f2c9878"
      },
      "source": [
        "train_input_ids = train_encoded_inputs['input_ids']\n",
        "train_attention_mask = train_encoded_inputs['attention_mask']\n",
        "train_token_type_ids = train_encoded_inputs['token_type_ids']\n",
        "train_labels = torch.tensor(train_labels_list)\n",
        "\n",
        "valid_input_ids = valid_encoded_inputs['input_ids']\n",
        "valid_attention_mask = valid_encoded_inputs['attention_mask']\n",
        "valid_token_type_ids = valid_encoded_inputs['token_type_ids']\n",
        "valid_labels = torch.tensor(valid_labels_list)\n",
        "\n",
        "test_input_ids = test_encoded_inputs['input_ids']\n",
        "test_attention_mask = test_encoded_inputs['attention_mask']\n",
        "test_token_type_ids = test_encoded_inputs['token_type_ids']\n",
        "test_labels = torch.tensor(test_labels_list)\n",
        "\n",
        "train_token_type_ids[0]\n",
        "tokenizer.decode(train_input_ids.tolist()[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'[CLS] \" i\\'m done \" : fed up with california, some vagrants look to texas [SEP] \" i\\'m done \" : fed up with pancakes, some conservatives look to texas [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_G4N1_nHDBS",
        "colab_type": "text"
      },
      "source": [
        "## Prepare mini-batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFBTt-rLGwOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BERT_Dataset(tud.Dataset):\n",
        "    def __init__(self, x1, x2, x3, y1):\n",
        "        self.len = x1.shape[0]\n",
        "\n",
        "        self.x1_data = x1.to(DEVICE)\n",
        "        self.x2_data = x2.to(DEVICE)\n",
        "        self.x3_data = x3.to(DEVICE)\n",
        "        self.y1_data = y1.to(DEVICE)\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x1_data[index], self.x2_data[index], self.x3_data[index], self.y1_data[index]\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAv8-n4iFcN0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "8c7a6e01-7067-46a9-c654-53bdf1577243"
      },
      "source": [
        "fix_seed()\n",
        "# Batching for BERT\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataset = BERT_Dataset(train_input_ids, train_attention_mask, train_token_type_ids, train_labels)\n",
        "valid_dataset = BERT_Dataset(valid_input_ids, valid_attention_mask, valid_token_type_ids, valid_labels)\n",
        "test_dataset = BERT_Dataset(test_input_ids, test_attention_mask, test_token_type_ids, test_labels)\n",
        "\n",
        "train_dataloader = tud.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "valid_dataloader = tud.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_dataloader = tud.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "\n",
        "##### demo #####\n",
        "print(train_dataloader)\n",
        "\n",
        "for x1, x2, x3, y1 in train_dataloader:\n",
        "    demo_x1 = x1\n",
        "    demo_x2 = x2\n",
        "    demo_x3 = x3\n",
        "    demo_y1 = y1\n",
        "    break\n",
        "    \n",
        "print(x1.shape)\n",
        "print(x2.shape)\n",
        "print(x3.shape)\n",
        "print(y1.shape)\n",
        "print(len(train_dataloader))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7f509778dcf8>\n",
            "torch.Size([32, 55])\n",
            "torch.Size([32, 55])\n",
            "torch.Size([32, 55])\n",
            "torch.Size([32])\n",
            "294\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYOPHhmj2IIp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ROBERTA_Dataset(tud.Dataset):\n",
        "    def __init__(self, x1, x2, y1):\n",
        "        self.len = x1.shape[0]\n",
        "\n",
        "        self.x1_data = x1.to(DEVICE)\n",
        "        self.x2_data = x2.to(DEVICE)\n",
        "        self.y1_data = y1.to(DEVICE)\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x1_data[index], self.x2_data[index], self.y1_data[index]\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEOVCXKU2ITm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fix_seed()\n",
        "# Batching for ROBERTA_Dataset\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "train_dataset = ROBERTA_Dataset(train_input_ids, train_attention_mask, train_labels)\n",
        "valid_dataset = ROBERTA_Dataset(valid_input_ids, valid_attention_mask, valid_labels)\n",
        "test_dataset = ROBERTA_Dataset(test_input_ids, test_attention_mask, test_labels)\n",
        "\n",
        "train_dataloader = tud.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "valid_dataloader = tud.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_dataloader = tud.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7SP8TiKLcL2",
        "colab_type": "text"
      },
      "source": [
        "# Training Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ry7hbzFyLFz6",
        "colab_type": "text"
      },
      "source": [
        "## Define accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IozWES_NudS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    returns accuracy per batch\n",
        "    \"\"\"\n",
        "\n",
        "    class_preds =  torch.argmax(F.softmax(preds, dim = 1), 1)\n",
        "    correct = (class_preds == y).float() # convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nx-ADOt3MlHg",
        "colab_type": "text"
      },
      "source": [
        "## Define train and evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oL8RT5k2Bn5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define train_BERT and evaluate_BERT\n",
        "def train_BERT(model, train_dataloader, valid_dataloader, optimizer, scheduler, N_EPOCHS):\n",
        "    fix_seed()\n",
        "    model = model.to(DEVICE)\n",
        "\n",
        "    # Measure the total time for the whole run.\n",
        "    t0 = time.time()\n",
        "\n",
        "    for epoch in range(N_EPOCHS):\n",
        "    \n",
        "        start_time = time.time()\n",
        "\n",
        "        # To ensure the dropout is \"turned on\" while training\n",
        "        model.train()\n",
        "        \n",
        "        epoch_loss = 0\n",
        "        epoch_acc = 0\n",
        "    \n",
        "        for input_ids_batch, attention_mask_batch, token_type_ids_batch, labels in train_dataloader:\n",
        "                        \n",
        "            # Zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # shape(input_ids_batch) = [B, T]\n",
        "            # shape(attention_mask_batch) = [B, T]\n",
        "            # shape(labels) = [B]\n",
        "\n",
        "            # get the output\n",
        "            outputs = model(input_ids_batch,\n",
        "                            attention_mask=attention_mask_batch,\n",
        "                            token_type_ids=token_type_ids_batch,\n",
        "                            labels=labels)\n",
        "            \n",
        "            # get the loss & the logits\n",
        "            loss = outputs[0]\n",
        "            logits = outputs[1]\n",
        "\n",
        "            # compute training accuracy\n",
        "            acc = accuracy(logits, labels)\n",
        "                      \n",
        "            # calculate the gradient of each parameter\n",
        "            loss.backward()\n",
        "        \n",
        "            # update the parameters using the gradients and optimizer algorithm \n",
        "            optimizer.step()\n",
        "\n",
        "            # update the learning rate\n",
        "            scheduler.step()\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "            \n",
        "        average_epoch_loss = epoch_loss / len(train_dataloader)\n",
        "        average_epoch_acc = epoch_acc / len(train_dataloader)\n",
        "        \n",
        "        end_time = time.time()\n",
        "               \n",
        "        epoch_mins, epoch_secs = run_time(start_time, end_time)\n",
        "    \n",
        "        average_epoch_valid_loss, average_epoch_valid_acc = evaluate_BERT(model, valid_dataloader)\n",
        "\n",
        "        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "        print(f'\\tTrain Loss: {average_epoch_loss:.5f} | Train Acc: {average_epoch_acc*100:.4f}%')\n",
        "        print(f'\\t Val. Loss: {average_epoch_valid_loss:.5f} |  Val. Acc: {average_epoch_valid_acc*100:.4f}%')\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"***Completed***\")\n",
        "    total_mins, total_secs = run_time(t0, time.time())\n",
        "    print(f'Total time spent: {total_mins}m {total_secs}s')\n",
        "\n",
        "    return average_epoch_loss, average_epoch_acc, average_epoch_valid_loss, average_epoch_valid_acc\n",
        "\n",
        "def evaluate_BERT(model, dataloader):\n",
        "    fix_seed()\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    # Turn on evaluate mode. This de-activates dropout. \n",
        "    model.eval()\n",
        "\n",
        "    # We do not compute gradients within this block, i.e. no training\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for input_ids_batch, attention_mask_batch, token_type_ids_batch, labels in dataloader:\n",
        "            \n",
        "            # get the output\n",
        "            outputs = model(input_ids_batch,\n",
        "                            attention_mask=attention_mask_batch,\n",
        "                            token_type_ids=token_type_ids_batch,\n",
        "                            labels=labels)\n",
        "\n",
        "            loss = outputs[0]\n",
        "            logits = outputs[1]\n",
        "            acc = accuracy(logits, labels)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(dataloader), epoch_acc / len(dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RWayHE225JVr",
        "colab": {}
      },
      "source": [
        "# define train_ROBERTA and evaluate_ROBERTA for RoBerta\n",
        "def train_ROBERTA(model, train_dataloader, valid_dataloader, optimizer, scheduler, N_EPOCHS):\n",
        "    fix_seed()\n",
        "    model = model.to(DEVICE)\n",
        "\n",
        "    # Measure the total time for the whole run.\n",
        "    t0 = time.time()\n",
        "\n",
        "    for epoch in range(N_EPOCHS):\n",
        "    \n",
        "        start_time = time.time()\n",
        "\n",
        "        # To ensure the dropout is \"turned on\" while training\n",
        "        model.train()\n",
        "        \n",
        "        epoch_loss = 0\n",
        "        epoch_acc = 0\n",
        "    \n",
        "        for input_ids_batch, attention_mask_batch, labels in train_dataloader:\n",
        "          \n",
        "            # Zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # shape(input_ids_batch) = [B, T]\n",
        "            # shape(attention_mask_batch) = [B, T]\n",
        "            # shape(labels) = [B]\n",
        "\n",
        "            # get the output\n",
        "            outputs = model(input_ids_batch,\n",
        "                            attention_mask=attention_mask_batch,\n",
        "                            labels=labels)\n",
        "            \n",
        "            # get the loss & the logits\n",
        "            loss = outputs[0]\n",
        "            logits = outputs[1]\n",
        "\n",
        "            # compute training accuracy\n",
        "            acc = accuracy(logits, labels)\n",
        "                      \n",
        "            # calculate the gradient of each parameter\n",
        "            loss.backward()\n",
        "        \n",
        "            # update the parameters using the gradients and optimizer algorithm \n",
        "            optimizer.step()\n",
        "\n",
        "            # update the learning rate\n",
        "            scheduler.step()\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "            \n",
        "        average_epoch_loss = epoch_loss / len(train_dataloader)\n",
        "        average_epoch_acc = epoch_acc / len(train_dataloader)\n",
        "        \n",
        "        end_time = time.time()\n",
        "               \n",
        "        epoch_mins, epoch_secs = run_time(start_time, end_time)\n",
        "    \n",
        "        average_epoch_valid_loss, average_epoch_valid_acc = evaluate_ROBERTA(model, valid_dataloader)\n",
        "\n",
        "        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "        print(f'\\tTrain Loss: {average_epoch_loss:.5f} | Train Acc: {average_epoch_acc*100:.4f}%')\n",
        "        print(f'\\t Val. Loss: {average_epoch_valid_loss:.5f} |  Val. Acc: {average_epoch_valid_acc*100:.4f}%')\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"***Completed***\")\n",
        "    total_mins, total_secs = run_time(t0, time.time())\n",
        "    print(f'Total time spent: {total_mins}m {total_secs}s')\n",
        "\n",
        "    return average_epoch_loss, average_epoch_acc, average_epoch_valid_loss, average_epoch_valid_acc\n",
        "\n",
        "def evaluate_ROBERTA(model, dataloader):\n",
        "    fix_seed()\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    # Turn on evaluate mode. This de-activates dropout. \n",
        "    model.eval()\n",
        "\n",
        "    # We do not compute gradients within this block, i.e. no training\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for input_ids_batch, attention_mask_batch, labels in dataloader:\n",
        "            \n",
        "            # get the output\n",
        "            outputs = model(input_ids_batch,\n",
        "                            attention_mask=attention_mask_batch,\n",
        "                            labels=labels)\n",
        "\n",
        "            loss = outputs[0]\n",
        "            logits = outputs[1]\n",
        "            acc = accuracy(logits, labels)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(dataloader), epoch_acc / len(dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsKLHwkSjU7R",
        "colab_type": "text"
      },
      "source": [
        "## Load pretrain LMs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gybOiDOojZHJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW\n",
        "\n",
        "# Load the BertForSequenceClassification model\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
        "                                                        num_labels = 3,   \n",
        "                                                        output_attentions = False,\n",
        "                                                        output_hidden_states = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-c-l3GY-CM5F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import AlbertForSequenceClassification, AdamW\n",
        "\n",
        "# Load the AlbertForSequenceClassification model\n",
        "model = AlbertForSequenceClassification.from_pretrained(\"albert-base-v2\",\n",
        "                                                        num_labels = 3,   \n",
        "                                                        output_attentions = False,\n",
        "                                                        output_hidden_states = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLuszp3W2HS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import ElectraForSequenceClassification, AdamW\n",
        "\n",
        "# Load the ElectraForSequenceClassification model\n",
        "model = ElectraForSequenceClassification.from_pretrained(\"google/electra-base-discriminator\",\n",
        "                                                        num_labels = 3,   \n",
        "                                                        output_attentions = False,\n",
        "                                                        output_hidden_states = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "albxeboih3Lt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import RobertaForSequenceClassification, AdamW\n",
        "\n",
        "# Load the RobertaForSequenceClassification model\n",
        "model = RobertaForSequenceClassification.from_pretrained('roberta-base',\n",
        "                                                    num_labels = 3,   \n",
        "                                                    output_attentions = False,\n",
        "                                                    output_hidden_states = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd8s9CZpXo9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import XLNetForSequenceClassification, AdamW\n",
        "\n",
        "# Load the XLNetForSequenceClassification model\n",
        "model = XLNetForSequenceClassification.from_pretrained('xlnet-base-cased',\n",
        "                                                    num_labels = 3,   \n",
        "                                                    output_attentions = False,\n",
        "                                                    output_hidden_states = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfnCDZLLUuVj",
        "colab_type": "text"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlF41zJHKurw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "d735ddea-11f4-48b4-de5f-ef39a65ec334"
      },
      "source": [
        "# Hyperparameters for BERT:\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4.\n",
        "N_EPOCHS = 4\n",
        "\n",
        "LRATE = 1e-5\n",
        "FRATE = \"none\"\n",
        "EPS = \"none\"\n",
        "WU = 0.06\n",
        "WDECAY = 0.1\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "TOTSTEPS = len(train_dataloader) * N_EPOCHS\n",
        "WUSTEPS = int(TOTSTEPS * WU)\n",
        "\n",
        "# Apply weight decay to all parameters other than bias and layer normalization terms\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': WDECAY},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "\n",
        "\"\"\"optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if \"transformer\" not in n], 'lr': LRATE, 'weight_decay': WDECAY},\n",
        "    {'params': [p for n, p in model.named_parameters() if \"transformer\" in n], 'weight_decay': WDECAY}\n",
        "]\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'optimizer_grouped_parameters = [\\n    {\\'params\\': [p for n, p in model.named_parameters() if \"transformer\" not in n], \\'lr\\': LRATE, \\'weight_decay\\': WDECAY},\\n    {\\'params\\': [p for n, p in model.named_parameters() if \"transformer\" in n], \\'weight_decay\\': WDECAY}\\n]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Y55KlMtWSvV",
        "colab_type": "text"
      },
      "source": [
        "## Optimizer & Learning Rate Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg-o8bvyBoDx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the optimizer, \n",
        "# the epsilon parameter is a very small number to prevent any division by zero\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=LRATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6uz9uWdBoH6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = WUSTEPS,\n",
        "                                            num_training_steps = TOTSTEPS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uv3-MI3pX2tr",
        "colab_type": "text"
      },
      "source": [
        "## Start training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7uePPEGBoMu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "24043731-ad3e-4b7a-dc2a-3fa5d41b8a48"
      },
      "source": [
        "train_loss, train_accuracy, val_loss, val_accuracy = train_BERT(model,\n",
        "                                                                train_dataloader,\n",
        "                                                                valid_dataloader,\n",
        "                                                                optimizer,\n",
        "                                                                scheduler,\n",
        "                                                                N_EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 1m 31s\n",
            "\tTrain Loss: 0.99479 | Train Acc: 45.0191%\n",
            "\t Val. Loss: 0.96465 |  Val. Acc: 45.7548%\n",
            "Epoch: 02 | Epoch Time: 1m 32s\n",
            "\tTrain Loss: 0.95419 | Train Acc: 47.6531%\n",
            "\t Val. Loss: 0.96574 |  Val. Acc: 47.0817%\n",
            "Epoch: 03 | Epoch Time: 1m 33s\n",
            "\tTrain Loss: 0.80342 | Train Acc: 66.9430%\n",
            "\t Val. Loss: 1.05948 |  Val. Acc: 47.4884%\n",
            "Epoch: 04 | Epoch Time: 1m 33s\n",
            "\tTrain Loss: 0.52005 | Train Acc: 84.2368%\n",
            "\t Val. Loss: 1.14986 |  Val. Acc: 48.5442%\n",
            "\n",
            "***Completed***\n",
            "Total time spent: 6m 40s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2m3M1cTNYNSu",
        "colab_type": "text"
      },
      "source": [
        "# Testing Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-l7wTEcYWIX",
        "colab_type": "text"
      },
      "source": [
        "## Start testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fk0nsayzYNtb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "89fd41e9-87db-4b1b-8b01-5ba74902b59f"
      },
      "source": [
        "fix_seed()\n",
        "\n",
        "test_loss = 0\n",
        "test_acc = 0\n",
        "test_logits_all = torch.tensor([], device=DEVICE)\n",
        "\n",
        "# Turn on evaluate mode. This de-activates dropout. \n",
        "model.eval()\n",
        "\n",
        "# We do not compute gradients within this block, i.e. no training\n",
        "with torch.no_grad():\n",
        "\n",
        "    for input_ids_batch, attention_mask_batch, token_type_ids_batch, labels in test_dataloader:\n",
        "        \n",
        "        # get the output\n",
        "        outputs = model(input_ids_batch,\n",
        "                        attention_mask=attention_mask_batch,\n",
        "                        token_type_ids=token_type_ids_batch,\n",
        "                        labels=labels)\n",
        "\n",
        "        loss_batch = outputs[0]\n",
        "        logits_batch = outputs[1]\n",
        "        #test_logits_all += logits_batch.tolist()\n",
        "        test_logits_all = torch.cat((test_logits_all, logits_batch), 0)\n",
        "        acc_batch = accuracy(logits_batch, labels)\n",
        "\n",
        "        test_loss += loss_batch.item()\n",
        "        test_acc += acc_batch.item()\n",
        "\n",
        "    average_test_loss = test_loss / len(test_dataloader)\n",
        "    average_test_acc = test_acc / len(test_dataloader)\n",
        "\n",
        "print(f'Test Loss: {average_test_loss:.5f} | Test Acc: {average_test_acc*100:.4f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 1.16847 | Test Acc: 45.1613%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wWcx1Wc0abJR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3874222c-2c13-42f6-b6d2-cf1b4257980a"
      },
      "source": [
        "# Test for the ROBERTA\n",
        "fix_seed()\n",
        "\n",
        "test_loss = 0\n",
        "test_acc = 0\n",
        "test_logits_all = torch.tensor([], device=DEVICE)\n",
        "\n",
        "# Turn on evaluate mode. This de-activates dropout. \n",
        "model.eval()\n",
        "\n",
        "# We do not compute gradients within this block, i.e. no training\n",
        "with torch.no_grad():\n",
        "\n",
        "    for input_ids_batch, attention_mask_batch, labels in test_dataloader:\n",
        "        \n",
        "        # get the output\n",
        "        outputs = model(input_ids_batch,\n",
        "                        attention_mask=attention_mask_batch,\n",
        "                        labels=labels)\n",
        "\n",
        "        loss_batch = outputs[0]\n",
        "        logits_batch = outputs[1]\n",
        "        #test_logits_all += logits_batch.tolist()\n",
        "        test_logits_all = torch.cat((test_logits_all, logits_batch), 0)\n",
        "        acc_batch = accuracy(logits_batch, labels)\n",
        "\n",
        "        test_loss += loss_batch.item()\n",
        "        test_acc += acc_batch.item()\n",
        "\n",
        "    average_test_loss = test_loss / len(test_dataloader)\n",
        "    average_test_acc = test_acc / len(test_dataloader)\n",
        "\n",
        "print(f'Test Loss: {average_test_loss:.5f} | Test Acc: {average_test_acc*100:.4f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 1.04915 | Test Acc: 45.0338%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBW5mocQjkB0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b92158d-2e8e-40fd-b166-e528aadfa607"
      },
      "source": [
        "test_logits_all.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2960, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 296
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmXyjzmkArMp",
        "colab_type": "text"
      },
      "source": [
        "## Write results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxAE4aJZQcyY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "25adbc35-7ae5-4569-dbbd-6fc0a90f83e7"
      },
      "source": [
        "def write_predictions(predictions, test_data_frame, out_loc):\n",
        "    test_data_frame['pred'] = predictions\n",
        "    output = test_data_frame[['id','pred']]\n",
        "    output.to_csv(out_loc, index=False)\n",
        "        \n",
        "    print('Output file created:\\n\\t- '+os.path.abspath(out_loc))\n",
        "\n",
        "\n",
        "# write the predictions for the dev data into 'task-2-output.csv'\n",
        "out_loc = 'gdrive/My Drive/subtask-2/task-2-output.csv'\n",
        "\n",
        "test_class_preds = torch.argmax(F.softmax(test_logits_all, dim = 1), 1)\n",
        "write_predictions(test_class_preds.cpu().numpy(), test, out_loc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output file created:\n",
            "\t- /content/gdrive/My Drive/subtask-2/task-2-output.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvRyvLeCFaPD",
        "colab_type": "text"
      },
      "source": [
        "## Check final results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzKVlMTJ88tg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b6b0e882-89c2-4e7b-bc3d-5d709054daf2"
      },
      "source": [
        "def score(truth_loc, prediction_loc):\n",
        "    truth = pd.read_csv(truth_loc, usecols=['id','label'])\n",
        "    pred = pd.read_csv(prediction_loc, usecols=['id','pred'])\n",
        "         \n",
        "    assert(sorted(truth.id) == sorted(pred.id)),\"ID mismatch between ground truth and prediction!\"\n",
        "    \n",
        "    data = pd.merge(truth,pred)\n",
        "    data = data[data.label != 0]\n",
        "    accuracy = (np.sum(data.label == data.pred)*1.0/len(data))*100\n",
        "    \n",
        "    print(\"Accuracy = %.6f\" % accuracy)\n",
        "\n",
        "    return accuracy   \n",
        "\n",
        "# print Accuracy\n",
        "truth_loc = 'gdrive/My Drive/subtask-2/test.csv'\n",
        "prediction_loc = 'gdrive/My Drive/subtask-2/task-2-output.csv'\n",
        "test_accuracy = score(truth_loc, prediction_loc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy = 50.304414\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tyk_hoF8safd",
        "colab_type": "text"
      },
      "source": [
        "# Logging Statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwpzJ5MG886_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "B1 = \"bert-base-uncased\"\n",
        "A2 = \"albert-base-v2\"\n",
        "E = \"electra\"\n",
        "XL = \"xlnet\"\n",
        "R = \"roberta\"\n",
        "\n",
        "training_stats, log_num = add_training_stats(training_stats, \n",
        "                                             log_num,\n",
        "                                             B1,\n",
        "                                             BATCH_SIZE, \n",
        "                                             N_EPOCHS,\n",
        "                                             \"{:.0e}\".format(LRATE),\n",
        "                                             FRATE, \n",
        "                                             EPS, \n",
        "                                             WU,\n",
        "                                             WDECAY, \n",
        "                                             train_loss, \n",
        "                                             train_accuracy*100, \n",
        "                                             val_loss, \n",
        "                                             val_accuracy*100,\n",
        "                                             test_accuracy\n",
        "                                             )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMDDYWnLsZiO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eff5e284-26a7-4a3b-dd10-d5fb6ba139f8"
      },
      "source": [
        "# Display floats with five decimal places.\n",
        "pd.set_option('precision', 5)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'log' as the row index.\n",
        "df_stats = df_stats.set_index('log')\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model Name</th>\n",
              "      <th>Batch Size</th>\n",
              "      <th>N_Epochs</th>\n",
              "      <th>lr</th>\n",
              "      <th>fr</th>\n",
              "      <th>eps</th>\n",
              "      <th>wu</th>\n",
              "      <th>wd</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Training Accur.</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Testing Accur.</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>log</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>xlnet</td>\n",
              "      <td>32</td>\n",
              "      <td>4</td>\n",
              "      <td>3e-05</td>\n",
              "      <td>none</td>\n",
              "      <td>1e-08</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.45450</td>\n",
              "      <td>83.26956</td>\n",
              "      <td>1.45902</td>\n",
              "      <td>43.38994</td>\n",
              "      <td>48.89650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>xlnet</td>\n",
              "      <td>32</td>\n",
              "      <td>2</td>\n",
              "      <td>8e-03</td>\n",
              "      <td>3e-05</td>\n",
              "      <td>1e-06</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.01</td>\n",
              "      <td>1.04101</td>\n",
              "      <td>43.85842</td>\n",
              "      <td>0.96483</td>\n",
              "      <td>43.24769</td>\n",
              "      <td>50.95129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>xlnet</td>\n",
              "      <td>32</td>\n",
              "      <td>2</td>\n",
              "      <td>5e-03</td>\n",
              "      <td>2e-05</td>\n",
              "      <td>1e-08</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.01</td>\n",
              "      <td>1.00768</td>\n",
              "      <td>44.62372</td>\n",
              "      <td>0.96349</td>\n",
              "      <td>44.73906</td>\n",
              "      <td>48.89650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>albert-base-v2</td>\n",
              "      <td>32</td>\n",
              "      <td>2</td>\n",
              "      <td>5e-03</td>\n",
              "      <td>2e-05</td>\n",
              "      <td>1e-08</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.01</td>\n",
              "      <td>1.01367</td>\n",
              "      <td>44.53869</td>\n",
              "      <td>0.96444</td>\n",
              "      <td>43.24769</td>\n",
              "      <td>50.95129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>albert-base-v2</td>\n",
              "      <td>32</td>\n",
              "      <td>2</td>\n",
              "      <td>5e-03</td>\n",
              "      <td>2e-05</td>\n",
              "      <td>1e-08</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.96267</td>\n",
              "      <td>44.72151</td>\n",
              "      <td>0.96402</td>\n",
              "      <td>43.24769</td>\n",
              "      <td>50.95129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>albert-base-v2</td>\n",
              "      <td>32</td>\n",
              "      <td>3</td>\n",
              "      <td>5e-03</td>\n",
              "      <td>2e-05</td>\n",
              "      <td>1e-08</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.97209</td>\n",
              "      <td>47.04719</td>\n",
              "      <td>0.96623</td>\n",
              "      <td>43.24769</td>\n",
              "      <td>50.95129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>albert-base-v2</td>\n",
              "      <td>32</td>\n",
              "      <td>4</td>\n",
              "      <td>3e-05</td>\n",
              "      <td>none</td>\n",
              "      <td>1e-08</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.88830</td>\n",
              "      <td>57.72534</td>\n",
              "      <td>0.99317</td>\n",
              "      <td>43.24769</td>\n",
              "      <td>50.95129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>albert-base-v2</td>\n",
              "      <td>32</td>\n",
              "      <td>2</td>\n",
              "      <td>3e-05</td>\n",
              "      <td>none</td>\n",
              "      <td>1e-08</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.96056</td>\n",
              "      <td>48.11437</td>\n",
              "      <td>0.95214</td>\n",
              "      <td>51.54027</td>\n",
              "      <td>50.41857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>albert-base-v2</td>\n",
              "      <td>32</td>\n",
              "      <td>2</td>\n",
              "      <td>3e-05</td>\n",
              "      <td>none</td>\n",
              "      <td>1e-08</td>\n",
              "      <td>none</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.96824</td>\n",
              "      <td>44.85332</td>\n",
              "      <td>0.96558</td>\n",
              "      <td>43.24769</td>\n",
              "      <td>50.91324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>albert-base-v2</td>\n",
              "      <td>32</td>\n",
              "      <td>2</td>\n",
              "      <td>3e-05</td>\n",
              "      <td>none</td>\n",
              "      <td>1e-08</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.95610</td>\n",
              "      <td>47.67432</td>\n",
              "      <td>0.96057</td>\n",
              "      <td>47.07726</td>\n",
              "      <td>50.87519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>albert-base-v2</td>\n",
              "      <td>32</td>\n",
              "      <td>3</td>\n",
              "      <td>3e-05</td>\n",
              "      <td>none</td>\n",
              "      <td>1e-08</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.94214</td>\n",
              "      <td>50.55485</td>\n",
              "      <td>0.96534</td>\n",
              "      <td>46.58828</td>\n",
              "      <td>50.87519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>roberta</td>\n",
              "      <td>32</td>\n",
              "      <td>3</td>\n",
              "      <td>3e-05</td>\n",
              "      <td>none</td>\n",
              "      <td>1e-08</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.95552</td>\n",
              "      <td>47.14923</td>\n",
              "      <td>0.96250</td>\n",
              "      <td>46.23489</td>\n",
              "      <td>48.85845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>roberta</td>\n",
              "      <td>32</td>\n",
              "      <td>3</td>\n",
              "      <td>3e-05</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.95899</td>\n",
              "      <td>45.75468</td>\n",
              "      <td>0.96309</td>\n",
              "      <td>45.79703</td>\n",
              "      <td>49.04871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>roberta</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>1e-05</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.80424</td>\n",
              "      <td>62.08475</td>\n",
              "      <td>1.02331</td>\n",
              "      <td>46.59347</td>\n",
              "      <td>49.54338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>bert-base-uncased</td>\n",
              "      <td>32</td>\n",
              "      <td>4</td>\n",
              "      <td>1e-05</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.57083</td>\n",
              "      <td>80.08078</td>\n",
              "      <td>1.11888</td>\n",
              "      <td>48.38416</td>\n",
              "      <td>51.56012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>bert-base-uncased</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>1e-05</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.38082</td>\n",
              "      <td>86.85051</td>\n",
              "      <td>1.37815</td>\n",
              "      <td>48.60642</td>\n",
              "      <td>50.22831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>bert-base-uncased</td>\n",
              "      <td>32</td>\n",
              "      <td>4</td>\n",
              "      <td>1e-05</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.55820</td>\n",
              "      <td>81.05867</td>\n",
              "      <td>1.13532</td>\n",
              "      <td>49.24431</td>\n",
              "      <td>50.68493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>bert-base-uncased</td>\n",
              "      <td>32</td>\n",
              "      <td>4</td>\n",
              "      <td>5e-06</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.83136</td>\n",
              "      <td>64.90221</td>\n",
              "      <td>0.99636</td>\n",
              "      <td>49.23097</td>\n",
              "      <td>49.88584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>bert-base-uncased</td>\n",
              "      <td>32</td>\n",
              "      <td>4</td>\n",
              "      <td>1e-05</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.52050</td>\n",
              "      <td>83.46088</td>\n",
              "      <td>1.13224</td>\n",
              "      <td>47.69737</td>\n",
              "      <td>50.68493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>bert-base-uncased</td>\n",
              "      <td>32</td>\n",
              "      <td>4</td>\n",
              "      <td>1e-05</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.53890</td>\n",
              "      <td>82.81250</td>\n",
              "      <td>1.14410</td>\n",
              "      <td>47.66847</td>\n",
              "      <td>50.30441</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Model Name  Batch Size  ...  Valid. Accur. Testing Accur.\n",
              "log                                 ...                              \n",
              "1                xlnet          32  ...       43.38994       48.89650\n",
              "2                xlnet          32  ...       43.24769       50.95129\n",
              "3                xlnet          32  ...       44.73906       48.89650\n",
              "4       albert-base-v2          32  ...       43.24769       50.95129\n",
              "5       albert-base-v2          32  ...       43.24769       50.95129\n",
              "6       albert-base-v2          32  ...       43.24769       50.95129\n",
              "7       albert-base-v2          32  ...       43.24769       50.95129\n",
              "8       albert-base-v2          32  ...       51.54027       50.41857\n",
              "9       albert-base-v2          32  ...       43.24769       50.91324\n",
              "10      albert-base-v2          32  ...       47.07726       50.87519\n",
              "11      albert-base-v2          32  ...       46.58828       50.87519\n",
              "12             roberta          32  ...       46.23489       48.85845\n",
              "13             roberta          32  ...       45.79703       49.04871\n",
              "14             roberta          16  ...       46.59347       49.54338\n",
              "15   bert-base-uncased          32  ...       48.38416       51.56012\n",
              "16   bert-base-uncased          16  ...       48.60642       50.22831\n",
              "17   bert-base-uncased          32  ...       49.24431       50.68493\n",
              "18   bert-base-uncased          32  ...       49.23097       49.88584\n",
              "19   bert-base-uncased          32  ...       47.69737       50.68493\n",
              "20   bert-base-uncased          32  ...       47.66847       50.30441\n",
              "\n",
              "[20 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 418
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFQZM8plDQyK",
        "colab_type": "text"
      },
      "source": [
        "## Write statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fg7-KYSf58QC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log_loc = 'gdrive/My Drive/subtask-2/log4.csv'\n",
        "df_stats.to_csv(log_loc, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1ZBR3Gx7Egy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljGh7wNTs03L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_stats.pop(-1)\n",
        "log_num -= 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk4Bjv555_cZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}